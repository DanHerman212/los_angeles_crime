{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# set the seaborn run command for font parameters\n",
    "# sns.set(rc={'font.weight': 'bold'}, font_scale=1.3)\n",
    "\n",
    "# set parameters to remove erroenous warning messages that clutter the notebook\n",
    "warnings.filterwarnings(\"ignore\", category=matplotlib.cbook.mplDeprecation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Business Understanding](#business-understanding)\n",
    "2. [Data Understanding](#data-understanding)\n",
    "3. [Data Preparation](#data-preparation)\n",
    "4. [Modeling](#modeling)\n",
    "5. [Evaluation](#evaluation)\n",
    "6. [Deployment](#deployment)\n",
    "\n",
    "## Business Understanding <a name=\"business-understanding\"></a>\n",
    "\n",
    "For this study, we will analyze serious crimes commited in Los Angeles for the period 2020 - 2024.\n",
    "\n",
    "There are 2 objectives for this study:\n",
    "1) Analyze serious crimes committed in Los Angeles, accroding to the National Crime Index\n",
    "2) Predict the clearance rate of serious crimes in Los Angeles to improve law enforcement outcomes and increase public safety\n",
    "\n",
    "Low crime clearance rates are a major concern for the Police and the public. The clearance rate is the proportion of crimes that result in an arrest. \n",
    "\n",
    "Assess the current situation:\n",
    "- What are trends in serious crimes being committed in Los Angeles today?\n",
    "- What is the current clearance rate for serious crimes in Los Angeles?\n",
    "\n",
    "Determining Data Mining Goals:\n",
    "- Insure that the crime incidents are appropriately labeled according to national crime index\n",
    "- Analyze impact to citizens as far as demographics, time of day, and location\n",
    "\n",
    "Project Plan for this study:\n",
    "- Collect the data from the LAPD public data sharing portal\n",
    "- Preprocess the data to ensure that it is clean and ready for analysis\n",
    "- Analyze the data to understand the trends in serious crimes in Los Angeles\n",
    "- Clean the data improving data quality, improving analysis insights and model performance\n",
    "- Create machine learning pipelines to pre-process the data and train the model\n",
    "- Evaluate the model to ensuring it's performance is accurate and interpretable\n",
    "\n",
    "\n",
    "## Data Understanding <a name=\"data-understanding\"></a>\n",
    "\n",
    "The data we collected from the LAPD includes the following observations:\n",
    "- 932,140 crimes reported\n",
    "- 21 different regional police districts\n",
    "- 120 unique labels classifying different crimes reported\n",
    "- 79 unique labels classifying different weapons used in the crimes reported\n",
    "- 306 unique labels classifying different locations where crimes were committed\n",
    "- 6 unique labels for crime status (arrest made, investigation continues)\n",
    "- Time Period - Full year data for 2020 - 2023 and Q1 for 2024\n",
    "\n",
    "There are 27 (omitting crime ID field) features included in the data cover the following topics:\n",
    "<br>\n",
    "- Date, Time, Location and Description of each crime comitted\n",
    "- Victim demographics (Age, Sex, Descent)\n",
    "- Type of location where crimes are committed (Apartment, Gas Station, etc)\n",
    "- Weapon used in the crime (Firearm, Knife, etc)\n",
    "- Status of the crime (Arrest made or continued investigation)\n",
    "- Geolocation\n",
    "\n",
    "### Data Quality\n",
    "The data quality is ok in general.  The critical features appear to be in good shape, with a negligble amount of missing values.  There is an issue with the `Part1-2`, label.  Part 1 crimes are serious crimes (according to the national crime index), while Part 2 crimes are less serious.  We will need to come up with a strategy to relable the data to differentiate between the two in our analysis.\n",
    "\n",
    "\n",
    "## Data Preparation <a name=\"data-preparation\"></a>\n",
    "We will take the following steps to create a high quality dataset\n",
    "\n",
    "1. Drop erroneous columns - Columns `CrmCd2`, `CrmCd3`, `CrmCd4` have between 95% - 99% missing values. We will drop these columns as they do not provide any valuable insight.<br><br>\n",
    "2. Temporal data - We will need to manually format date and time columns, including `DateRptd`,`DATEOCC`,`TIMEOCC`<br><br>\n",
    "3. Text and Categorical Data - We will create machine learning pipelines using TFIDF to vectorize the text data and one hot encoding to transform the categorical data\n",
    "\n",
    "### Feature Engineering\n",
    "We will add the following features to improve data quality for more granular analysis:\n",
    "- `Year` - Extract year from `DATEOCC`\n",
    "- `Month` - Extract month from `DATEOCC`\n",
    "- `Day` - Extract day from  `DATEOCC`\n",
    "- `Part of Day` - Descritize `TIMEOCC` into 4 intervals (Morning, Afternoon, Evening, Night)\n",
    "- `Target` - Create a target variable indicating if the suspect was arrested or if the investigation is ongoing\n",
    "\n",
    "### Data Visualization\n",
    "We will create an interactive map which shows the concentration of crime activity per region, with some written analysis to observe patterns in crime concentration.\n",
    "\n",
    "## Modeling <a name=\"modeling\"></a>\n",
    "\n",
    "We will use an XGBoost predictive model to predict the clearance rate of serious crimes in Los Angeles.  We will use the following steps to create the model:\n",
    "\n",
    "1. Create a development, training and test datasets to train the model\n",
    "2. Create a machine learning pipeline to preprocess the data\n",
    "3. Create a parameter grid to choose ideal hyperparameters to optimize the model\n",
    "\n",
    "\n",
    "## Evaluation <a name=\"evaluation\"></a>\n",
    "\n",
    "Evaluate the performance of the models.\n",
    "\n",
    "## Deployment <a name=\"deployment\"></a>\n",
    "\n",
    "Deploy the models into production.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
